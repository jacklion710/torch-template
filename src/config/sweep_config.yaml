# Sweep configuration
program: src/train.py
method: random  # bayes, random, or grid
metric:
  name: val/loss
  goal: minimize  # minimize or maximize

# Parameter search space
parameters:
  # Model architecture parameters
  models.generator.params.latent_dim:
    values: [64, 128, 256]
  
  models.generator.params.hidden_dims:
    values: 
      - [256, 128, 64]
      - [512, 256, 128, 64]
      - [1024, 512, 256, 128]
  
  models.generator.params.dropout_rate:
    distribution: uniform
    min: 0.0
    max: 0.5
  
  # Training hyperparameters
  training.optimizers.generator.params.lr:
    distribution: log_uniform
    min: -9.21  # log(0.0001)
    max: -4.61  # log(0.01)
  
  training.optimizers.discriminator.params.lr:
    distribution: log_uniform
    min: -9.21  # log(0.0001)
    max: -4.61  # log(0.01)
  
  training.optimizers.generator.params.weight_decay:
    values: [0.0, 0.0001, 0.001]
  
  # Data parameters
  data.train_dataloader_params.batch_size:
    values: [16, 32, 64, 128]
  
  # Loss weights
  training.losses.reconstruction.weight:
    distribution: uniform
    min: 0.1
    max: 10.0
  
  training.losses.adversarial.weight:
    distribution: uniform
    min: 0.01
    max: 1.0

# Resource limits per trial
run_cap: 500  # Maximum number of runs
timeout: 43200  # Maximum runtime in seconds (12 hours)

# Additional sweep metadata
name: "optimization_sweep"
description: "Hyperparameter optimization sweep for model training"
project: "your_project_name"
